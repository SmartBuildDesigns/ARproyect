# Realidad Aumentada con OpenCV, Pygame y OpenGL

Este proyecto es una aplicaci√≥n de Realidad Aumentada (RA) basada en marcadores, desarrollada completamente en Python. Utiliza un tablero de ajedrez como marcador f√≠sico para detectar una superficie y superponer un modelo 3D en tiempo real sobre la transmisi√≥n de video de una c√°mara web.

![Ejemplo de la App en funcionamiento](https://i.imgur.com/AR-demo.gif) ---

## üõ†Ô∏è Tecnolog√≠as Utilizadas
* **OpenCV:** Para la captura de video, correcci√≥n de imagen, detecci√≥n del marcador (tablero de ajedrez) y el c√°lculo de la pose de la c√°mara.
* **PyOpenGL:** Para todo el renderizado de la escena 3D, incluyendo el modelo, la iluminaci√≥n y las texturas.
* **Pygame:** Para la creaci√≥n de la ventana, el contexto de OpenGL y la gesti√≥n de eventos de teclado.
* **PyWavefront:** Para la carga de modelos 3D en el popular formato `.obj`.
* **NumPy:** Para todas las operaciones num√©ricas y matriciales de alto rendimiento.

---

## ‚ú® Caracter√≠sticas Principales
* **Tracking en Tiempo Real:** Detecta un tablero de ajedrez y sigue su posici√≥n y orientaci√≥n (pose) con alta precisi√≥n.
* **Renderizado de Modelos 3D:** Carga y muestra archivos `.obj` sobre el marcador, creando la ilusi√≥n de que el objeto est√° en el mundo real.
* **Control Interactivo:** Permite rotar el modelo en sus tres ejes y cambiar el modo de visualizaci√≥n (caras s√≥lidas, malla de alambre o puntos).
* **Control de Nivel de Detalle (LOD):** Aumenta o disminuye din√°micamente la complejidad del modelo para optimizar el rendimiento, mostrando m√°s o menos caras.
* **Captura de Pantalla:** Guarda una imagen de la escena de RA actual con solo presionar una tecla.

---

## ‚öôÔ∏è Requisitos e Instalaci√≥n
Necesitas tener **Python 3** instalado. Puedes instalar todas las dependencias del proyecto ejecutando el siguiente comando en tu terminal:
```bash
pip install opencv-python numpy pygame PyOpenGL pywavefront Pillow
```

---

## üöÄ C√≥mo Ejecutar el Proyecto

1.  **Calibrar la C√°mara:** Antes que nada, debes calibrar tu c√°mara. Generalmente, esto implica ejecutar un script de calibraci√≥n por separado que te pide mostrarle un tablero de ajedrez desde diferentes √°ngulos. Este proceso genera el archivo `calibracion_camara.npz`, que es vital para la precisi√≥n de la aplicaci√≥n.
2.  **Imprimir el Marcador:** Necesitar√°s un tablero de ajedrez f√≠sico con un patr√≥n de **9x6 esquinas internas**. Este es el marcador que la c√°mara buscar√°.
3.  **Ejecutar la Aplicaci√≥n:**
    ```bash
    python main.py
    ```
4.  **Enfocar el Marcador:** Apunta la c√°mara hacia el tablero de ajedrez. Una vez que lo detecte, el modelo 3D aparecer√° sobre √©l.

---

## ‚å®Ô∏è Controles
* **`w` / `p` / `f`**: Cambiar modo de vista (Wireframe / Puntos / Caras).
* **`r` / `t` / `y`**: Rotar el modelo en los ejes X, Y, Z. (Mant√©n `SHIFT` para rotar en sentido contrario).
* **`+` / `-`**: Aumentar/disminuir el tama√±o de los puntos y el grosor de las l√≠neas.
* **`[`**: Disminuir el detalle del modelo (renderiza menos caras).
* **`]`**: Aumentar el detalle del modelo (renderiza m√°s caras).
* **`s`**: Tomar una captura de pantalla (se guarda en la carpeta del proyecto).
* **`q` / `ESC`**: Salir del programa.

---

## üî¨ La Importancia Crucial de la Calibraci√≥n de la C√°mara

Para que la Realidad Aumentada funcione, el mundo virtual 3D y el mundo real deben estar perfectamente alineados. La calibraci√≥n de la c√°mara es el puente que hace posible esta alineaci√≥n. Sin ella, la ilusi√≥n se rompe por completo.

Una c√°mara no es un dispositivo de medici√≥n perfecto; su lente introduce **distorsi√≥n** y sus propiedades internas (como la distancia focal) son desconocidas para el programa. La calibraci√≥n resuelve estos dos problemas.


*A la izquierda, una imagen con distorsi√≥n. A la derecha, la misma imagen corregida digitalmente gracias a los par√°metros de calibraci√≥n.*

### Los Par√°metros de Calibraci√≥n

El proceso de calibraci√≥n genera dos piezas clave de informaci√≥n:

1.  **`dist` (Coeficientes de Distorsi√≥n):** Un conjunto de valores que describen matem√°ticamente c√≥mo la lente deforma la imagen. Son la "receta" para revertir esta distorsi√≥n y "enderezar" la imagen.
2.  **`mtx` (Matriz Intr√≠nseca):** Una matriz de 3x3 que contiene el "ADN" geom√©trico de la c√°mara:
    * **`fx`, `fy` (Distancia Focal):** Definen el campo de visi√≥n y la perspectiva de la c√°mara.
    * **`cx`, `cy` (Punto Principal):** Las coordenadas del centro √≥ptico exacto del sensor.

### ¬øC√≥mo se Usan en el C√≥digo?

Estos par√°metros son utilizados en tres pasos cr√≠ticos:

1.  **`cv2.undistort()`:** Antes de cualquier an√°lisis, el fotograma capturado se "limpia" usando los coeficientes `dist`. Esto asegura que todas las l√≠neas rectas del mundo real sean rectas en la imagen procesada, permitiendo una detecci√≥n precisa de las esquinas del marcador.
    ```python
    frame_undist = cv2.undistort(frame, mtx, dist, None, mtx)
    ```

2.  **`cv2.solvePnP()`:** Esta funci√≥n calcula la posici√≥n y rotaci√≥n 3D del marcador. Para poder traducir las coordenadas 2D de las esquinas detectadas en la imagen a una pose 3D, **necesita la matriz `mtx`**. Esta matriz le proporciona el contexto de la perspectiva de la c√°mara, permiti√©ndole resolver la pose correctamente.
    ```python
    _, rvec, tvec = cv2.solvePnP(objp, corners2, mtx, dist)
    ```

3.  **`set_projection_from_camera()`:** Finalmente, para que el objeto 3D se dibuje con la misma perspectiva que el mundo real, la "c√°mara virtual" de OpenGL debe imitar perfectamente a la c√°mara real. Esta funci√≥n utiliza los valores `fx, fy, cx, cy` de la matriz `mtx` para construir la matriz de proyecci√≥n de OpenGL.
    ```python
    def set_projection_from_camera(mtx):
        # ... extrae fx, fy, cx, cy de mtx para configurar glFrustum
    ```

En resumen, la calibraci√≥n establece una **cadena de precisi√≥n matem√°tica**. Sin ella, la detecci√≥n ser√≠a inexacta, el c√°lculo de la pose 3D ser√≠a incorrecto y el renderizado virtual no coincidir√≠a con la perspectiva real, resultando en un objeto 3D que tiembla, se desliza y no se siente anclado al mundo real.

## Entendiendo los Archivos 3D: `.obj`, `.mtl` y las Texturas

Para que un objeto 3D se vea realista, necesita m√°s que solo una forma. Necesita color, material y detalles en su superficie. En este proyecto, esto se logra a trav√©s de una combinaci√≥n de tres tipos de archivos:

1.  **El Modelo (`.obj`):** Define la **geometr√≠a** del objeto.
2.  **El Material (`.mtl`):** Describe **c√≥mo se ve la superficie** (color, brillo, etc.).
3.  **La Textura (`.png`, `.jpg`):** Es la **imagen que "envuelve"** al modelo para darle detalle.


*A la izquierda, un modelo 3D solo con su geometr√≠a. A la derecha, el mismo modelo con materiales y texturas aplicadas.*

### 1. El Formato de Malla: `.obj` (Wavefront OBJ)

El archivo `.obj` es uno de los formatos de modelos 3D m√°s antiguos y populares, principalmente porque es de **texto plano** y muy f√°cil de interpretar. Se encarga de definir la **estructura o "esqueleto"** del modelo.

Dentro de un archivo `.obj`, encontrar√°s principalmente estas l√≠neas:
* `v` (V√©rtice): Define un punto en el espacio 3D con coordenadas X, Y, Z. Son los "ladrillos" fundamentales de la malla.
    ```
    v 1.000000 0.500000 -0.250000
    ```
* `vt` (V√©rtice de Textura): Define una coordenada 2D (U, V) que indica qu√© punto de la imagen de textura corresponde a un v√©rtice de la malla.
    ```
    vt 0.500000 0.500000
    ```
* `vn` (Normal de V√©rtice): Define la orientaci√≥n de la superficie en un v√©rtice, lo cual es crucial para calcular c√≥mo la luz rebota en el objeto.
    ```
    vn 0.000000 1.000000 0.000000
    ```
* `f` (Cara): Define una cara poligonal (generalmente un tri√°ngulo o un cuadrado) conectando varios v√©rtices. Esta es la l√≠nea que finalmente "construye" la superficie.
    ```
    # Formato: v√©rtice/v√©rtice_textura/normal
    f 1/1/1 2/2/1 3/3/1
    ```

**Importante:** El archivo `.obj` no contiene informaci√≥n de color o material. Para eso, hace referencia a otro archivo.

### 2. La Librer√≠a de Materiales: `.mtl` (Material Template Library)

El archivo `.obj` generalmente incluye una l√≠nea al principio que enlaza a su archivo de materiales:
```
mtllib mi_modelo.mtl
```

El archivo `.mtl` es tambi√©n un archivo de texto que describe las propiedades de la superficie. Dentro de √©l, se definen uno o m√°s materiales. Las directivas m√°s comunes son:

* `newmtl NombreDelMaterial`: Inicia la definici√≥n de un nuevo material.
* `Ka`, `Kd`, `Ks`: Definen los colores **Ambiente**, **Difuso** y **Especular** del material en formato RGB.
    * **Color Difuso (`Kd`):** Es el color base del objeto bajo luz blanca directa.
    * **Color Especular (`Ks`):** Es el color del reflejo brillante (el "brillo" en un objeto pulido).
* `Ns`: Define el **brillo especular** (un valor alto crea un reflejo peque√±o y concentrado, como en el metal; un valor bajo crea uno amplio, como en el pl√°stico).
* **`map_Kd`**: ¬°Esta es la directiva m√°s importante para las texturas! Le dice al motor de renderizado que **use una imagen como el color difuso** del material.

```mtl
# Ejemplo de un archivo .mtl

newmtl MaterialLucario
Ns 250.0
Ka 1.0 1.0 1.0  # Luz ambiental
Kd 0.8 0.8 0.8  # Color difuso (base)
Ks 0.5 0.5 0.5  # Color del brillo especular
map_Kd textura_lucario.png  # <--- ¬°Aqu√≠ se enlaza la imagen de la textura!
```

### 3. La Textura: Archivos de Imagen (`.png`, `.jpg`, etc.)

Este es el archivo de imagen que `map_Kd` especifica. La **textura** es una imagen 2D que se "envuelve" alrededor del modelo 3D siguiendo las coordenadas `vt` definidas en el archivo `.obj`. Este proceso, llamado **UV mapping**, es lo que permite que un simple pol√≠gono parezca tener detalles complejos como piel, tela, madera o metal.



### La Relaci√≥n en Conjunto

El flujo de trabajo es el siguiente:

1.  `main.py` carga el `Lucario.obj` usando `pywavefront`.
2.  `pywavefront` lee el `.obj` y ve la l√≠nea `mtllib Lucario.mtl`.
3.  Autom√°ticamente, carga el `Lucario.mtl` para obtener las propiedades de los materiales.
4.  Al leer el material, encuentra la directiva `map_Kd Lucario_Textura.png`.
5.  Finalmente, carga la imagen `Lucario_Textura.png` y la prepara para que OpenGL la "pinte" sobre la geometr√≠a del `.obj` cuando se renderice.

Comprender esta separaci√≥n entre **forma (`.obj`)**, **superficie (`.mtl`)** e **imagen (`.png`)** es clave para trabajar con cualquier tipo de gr√°ficos 3D.

## De la C√°mara a OpenGL: La Transformaci√≥n M√°gica

Una vez que tenemos los par√°metros de calibraci√≥n (`mtx`, `dist`) y la pose del marcador en el mundo real (`rvec`, `tvec` de `solvePnP`), nos enfrentamos al √∫ltimo gran desaf√≠o: **traducir esta informaci√≥n al lenguaje de OpenGL**.

Esto no es directo, ya que OpenCV y OpenGL "ven" el mundo de maneras diferentes; usan **sistemas de coordenadas distintos**.

* **OpenCV (C√°mara):** Considera que **+Y** es hacia **abajo** y **+Z** es hacia **adelante** (saliendo de la pantalla hacia el espectador).
* **OpenGL (C√°mara):** Considera que **+Y** es hacia **arriba** y **-Z** es hacia **adelante**.


*Comparaci√≥n de los sistemas de coordenadas. Es necesario un ajuste para que ambos "mundos" coincidan.*

Para alinear el objeto 3D virtual con el mundo real, debemos configurar dos matrices principales en OpenGL: la matriz de **Vista (Model-View)** y la de **Proyecci√≥n**.

---

### 1. La Matriz de Vista (Model-View): Posicionando el Mundo

La matriz de Vista le dice a OpenGL desde d√≥nde y con qu√© orientaci√≥n se est√° mirando la escena. En nuestro caso, esta matriz debe replicar la pose exacta de nuestra c√°mara web real.

El proceso en el c√≥digo es el siguiente:

1.  **Obtener Pose:** `cv2.solvePnP` nos da un vector de rotaci√≥n (`rvec`) y uno de traslaci√≥n (`tvec`) que describen la pose del marcador en el sistema de coordenadas de OpenCV.

2.  **Convertir a Matriz:** La rotaci√≥n `rvec` se convierte en una matriz de rotaci√≥n de 3x3, `R`, usando `cv2.Rodrigues(rvec)`.

3.  **Crear Matriz de Pose:** Se combina la matriz de rotaci√≥n `R` y el vector de traslaci√≥n `tvec` en una sola matriz de transformaci√≥n de 4x4 (`pose_matrix`).

4.  **Corregir Coordenadas:** Aqu√≠ est√° el paso crucial. Antes de pasarle la `pose_matrix` a OpenGL, la multiplicamos por una matriz de conversi√≥n que invierte los ejes Y y Z para adaptarlos al sistema de OpenGL.
    ```python
    # Esta matriz voltea el signo de los ejes Y y Z
    gl_convert = np.array([[1, 0, 0, 0],
                           [0,-1, 0, 0],
                           [0, 0,-1, 0],
                           [0, 0, 0, 1]])
    
    # Se establece el modo de matriz y se carga la conversi√≥n
    glMatrixMode(GL_MODELVIEW)
    glLoadIdentity()
    glMultMatrixf(gl_convert.T) # .T es para transponer la matriz
    
    # Ahora se multiplica por la pose del marcador
    glMultMatrixf(pose_matrix.T)
    ```
Al hacer esto, hemos movido y rotado toda la escena de OpenGL para que la c√°mara virtual quede perfectamente alineada con la c√°mara real respecto al marcador.

---

### 2. La Matriz de Proyecci√≥n: Imitando el Lente de la C√°mara

La matriz de Proyecci√≥n define las propiedades del "lente" de la c√°mara virtual: su campo de visi√≥n, su relaci√≥n de aspecto y c√≥mo se representa la perspectiva. Para que la ilusi√≥n sea perfecta, este lente virtual debe ser un clon del lente de nuestra c√°mara web.

Aqu√≠ es donde la **matriz intr√≠nseca (`mtx`)** vuelve a ser protagonista. La funci√≥n `set_projection_from_camera` realiza esta tarea:

1.  **Extraer Par√°metros:** La funci√≥n toma la matriz `mtx` y extrae los valores de distancia focal (`fx`, `fy`) y el punto principal (`cx`, `cy`).
    $$
    mtx = \begin{pmatrix} f_x & 0 & c_x \\ 0 & f_y & c_y \\ 0 & 0 & 1 \end{pmatrix}
    $$

2.  **Construir un Frustum:** OpenGL no usa directamente estos valores, pero s√≠ una funci√≥n llamada `glFrustum`. Esta funci√≥n define la pir√°mide de visi√≥n de la c√°mara. El c√≥digo utiliza f√≥rmulas matem√°ticas para convertir `fx, fy, cx, cy` en los par√°metros (`left`, `right`, `bottom`, `top`) que `glFrustum` necesita.
    ```python
    def set_projection_from_camera(mtx):
        glMatrixMode(GL_PROJECTION)
        glLoadIdentity()
        fx, fy = mtx[0, 0], mtx[1, 1]
        cx, cy = mtx[0, 2], mtx[1, 2]
        
        # Calcular los bordes de la pir√°mide de visi√≥n
        left   = -cx * z_near / fx
        right  = (width - cx) * z_near / fx
        bottom = -(height - cy) * z_near / fy
        top    = cy * z_near / fy
        
        # Establecer la proyecci√≥n de OpenGL para que coincida con la c√°mara
        glFrustum(left, right, bottom, top, z_near, z_far)
    ```
Este paso garantiza que los objetos 3D se rendericen con la misma distorsi√≥n de perspectiva que captura la c√°mara real, completando as√≠ la integraci√≥n entre el mundo real y el virtual.
